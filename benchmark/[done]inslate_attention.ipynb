{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4945fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from src.datasets import RL4RS, ContentWise, DummyData, OpenCDP\n",
    "from src.utils import train, get_dummy_data, get_train_val_test_tmatrix_tnumitems, get_svd_encoder\n",
    "from src.embeddings import RecsysEmbedding\n",
    "\n",
    "experiment_name = 'InSlateAttention'\n",
    "device = 'cuda:2'\n",
    "seed = 123\n",
    "pkl_path = '../pkl/'\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f1440",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c87c94",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e63c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "class AttentionResponseModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    No recurrent dependency, just slate-wise attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding, nheads=2, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding.embedding_dim\n",
    "        self.embedding = embedding\n",
    "        self.attention= torch.nn.MultiheadAttention(\n",
    "            2 * embedding.embedding_dim,\n",
    "            num_heads=nheads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.out_layer = torch.nn.Linear(2 * embedding.embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        item_embs, user_embs = self.embedding(batch)\n",
    "        shp = item_embs.shape\n",
    "        \n",
    "        # let model attent to first padd token if slate is empty to avoid NaN gradients\n",
    "        # (anyway they does not contrinute into metrics computation)\n",
    "        key_padding_mask = batch['slates_mask'].clone()\n",
    "        key_padding_mask[:,:, 0] = True \n",
    "        \n",
    "        # repeating user embedding for each item embeding\n",
    "        features = torch.cat(\n",
    "            [\n",
    "                item_embs,\n",
    "                user_embs[:, :, None, :].repeat(1, 1, shp[-2], 1).reshape(shp)\n",
    "            ],\n",
    "            dim = -1\n",
    "        )\n",
    "        \n",
    "        # all recomendations in session are scored independently\n",
    "        features = features.flatten(0,1)\n",
    "        \n",
    "        features, attn_map = self.attention(\n",
    "            features, features, features,\n",
    "            key_padding_mask=~key_padding_mask.flatten(0, 1)\n",
    "        )\n",
    "        \n",
    "        # transforming back to sequence shape\n",
    "        shp = list(shp)\n",
    "        shp[-1] *= 2\n",
    "        return self.out_layer(features.reshape(shp)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fecc3ce",
   "metadata": {},
   "source": [
    "# Игрушечный датасет: проверим, что сходится к идеальным метрикам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DummyData()\n",
    "dummy_loader, dummy_matrix = get_dummy_data(d)\n",
    "\n",
    "model = AttentionResponseModel(\n",
    "    RecsysEmbedding(d.n_items, dummy_matrix, embeddings='neural').to('cpu'),\n",
    "    output_dim=1\n",
    ").to('cpu')\n",
    "\n",
    "train(\n",
    "    model, \n",
    "    dummy_loader, dummy_loader, dummy_loader,\n",
    "    device=device, lr=1e-3, num_epochs=5000, dummy=True,\n",
    "    silent=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a07300",
   "metadata": {},
   "source": [
    "# ContentWise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_wise_results = []\n",
    "dataset = ContentWise.load(os.path.join(pkl_path, 'cw.pkl'))\n",
    "(\n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    test_loader, \n",
    "    train_user_item_matrix, \n",
    "    train_num_items \n",
    ") = get_train_val_test_tmatrix_tnumitems(dataset, batch_size=150)\n",
    "\n",
    "print(f\"{len(dataset)} data points among {len(train_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f92842-6ea6-4275-ae6f-4ef429d9450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embeddings in ['svd', 'neural']:\n",
    "    print(f\"\\nEvaluating {experiment_name} with {embeddings} embeddings\")\n",
    "    \n",
    "    model = AttentionResponseModel(\n",
    "        RecsysEmbedding(train_num_items, train_user_item_matrix, embeddings=embeddings),\n",
    "        output_dim=1\n",
    "    ).to(device)\n",
    "\n",
    "    _, metrics = train(\n",
    "        model, \n",
    "        train_loader, val_loader, test_loader, \n",
    "        device=device, lr=1e-3, num_epochs=5000, early_stopping=7,\n",
    "       silent=True, \n",
    "    )\n",
    "    \n",
    "    metrics['embeddings'] = embeddings\n",
    "    content_wise_results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522ab19-c02d-4a5f-8a99-884c124f5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(content_wise_results).to_csv(f'results/cw_{experiment_name}.csv')\n",
    "del dataset, train_loader, val_loader, test_loader, train_user_item_matrix, train_num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ee60f",
   "metadata": {},
   "source": [
    "# RL4RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5653bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl4rs_results = []\n",
    "dataset = RL4RS.load(os.path.join(pkl_path, 'rl4rs.pkl'))\n",
    "(\n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    test_loader, \n",
    "    train_user_item_matrix, \n",
    "    train_num_items \n",
    ") = get_train_val_test_tmatrix_tnumitems(dataset, batch_size=350)\n",
    "\n",
    "print(f\"{len(dataset)} data points among {len(train_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3951d43-fb42-4aca-b71b-0f6ed7eb6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embeddings in ['neural','explicit', 'svd',  ]:\n",
    "    print(f\"\\nEvaluating {experiment_name} with {embeddings} embeddings\")\n",
    "\n",
    "    model = AttentionResponseModel(\n",
    "        RecsysEmbedding(\n",
    "            train_num_items, \n",
    "            train_user_item_matrix, \n",
    "            embeddings=embeddings,\n",
    "            embedding_dim=40\n",
    "        ),\n",
    "        output_dim=1\n",
    "    ).to(device)\n",
    "\n",
    "    best_model, metrics = train(\n",
    "        model, \n",
    "        train_loader, val_loader, test_loader, \n",
    "        device=device, lr=1e-3, num_epochs=5000, early_stopping=7,\n",
    "        silent=True\n",
    "    )\n",
    "    \n",
    "    metrics['embeddings'] = embeddings\n",
    "    rl4rs_results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6fde63-9cc6-4eda-b0a5-a75ca1083c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rl4rs_results).to_csv(f'results/rl4rs_{experiment_name}.csv')\n",
    "del dataset, train_loader, val_loader, test_loader, train_user_item_matrix, train_num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e5900-91e5-484e-be29-5324ac09623d",
   "metadata": {},
   "source": [
    "# OpenCDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a39b4d-0f89-40bc-aaac-a4a2cdca1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in ['cosmetics', 'multi']:\n",
    "    for filename in os.listdir(pkl_path):    \n",
    "        result = []\n",
    "        if not filename.startswith(group):\n",
    "            continue\n",
    "        print(f\"\\n == {filename} ==\")\n",
    "        dataset = OpenCDP.load(os.path.join(pkl_path, filename))\n",
    "        (\n",
    "            train_loader, \n",
    "            val_loader,\n",
    "            test_loader, \n",
    "            train_user_item_matrix, \n",
    "            train_num_items\n",
    "        ) = get_train_val_test_tmatrix_tnumitems(dataset, batch_size=800)\n",
    "    \n",
    "        print(f\"{len(dataset)} data points among {len(train_loader)} batches\")\n",
    "        for embeddings in ['neural', 'svd']:\n",
    "            print(f\"\\nEvaluating {experiment_name} with {embeddings} embeddings\")\n",
    "\n",
    "            model = AttentionResponseModel(\n",
    "                RecsysEmbedding(train_num_items, train_user_item_matrix, embeddings=embeddings),\n",
    "                output_dim=1\n",
    "            ).to(device)\n",
    "\n",
    "            best_model, metrics = train(\n",
    "                model, \n",
    "                train_loader, val_loader, test_loader, \n",
    "                device=device, lr=1e-3, num_epochs=5000, early_stopping=7,\n",
    "                silent=True\n",
    "            )\n",
    "            \n",
    "            print(metrics)\n",
    "            metrics['embeddings'] = embeddings\n",
    "            result.append(metrics)\n",
    "        pd.DataFrame(result).to_csv(f'results/{filename}_{experiment_name}.csv')\n",
    "        del dataset, train_loader, val_loader, test_loader, train_user_item_matrix, train_num_items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
