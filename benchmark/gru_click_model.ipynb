{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a18c67a-c6f7-4e93-82af-d7f17511b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from src.datasets import RL4RS, ContentWise, DummyData\n",
    "from src.utils import train, get_dummy_data, get_train_val_test_svd\n",
    "\n",
    "experiment_name = 'FlattenedGRU'\n",
    "device = 'cuda:0'\n",
    "seed = 1337\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cd7475-d005-474b-a6f2-c73e3e4432de",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abd0c9-7428-4033-9997-f7e5b1091e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class NeuralClickModel(torch.nn.Module):\n",
    "    def __init__(self, user_embedding_dim=42, item_embedding_dim=40, num_items=None, num_users=None, \n",
    "                 embeddings='explicit', output_dim=1):\n",
    "        super().__init__()\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        self.user_embedding_dim = user_embedding_dim\n",
    "        self.embeddings = embeddings\n",
    "        if embeddings == 'neural':\n",
    "            self.user_embedding = torch.nn.Embedding(num_users, user_embedding_dim)\n",
    "            self.item_embedding = torch.nn.Embedding(num_items, item_embedding_dim)\n",
    "        \n",
    "        self.rnn_layer = torch.nn.GRU(input_size=self.item_embedding_dim, hidden_size=self.user_embedding_dim, batch_first=True)\n",
    "        self.out_layer = torch.nn.Linear(self.user_embedding_dim, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # consider sequential clicks, hence need to flatten slates\n",
    "        if self.embeddings == 'neural':\n",
    "            user_embs = self.user_embedding(batch['user_indexes'])[:,0,:].unsqueeze(0).contiguous()\n",
    "            item_embs = self.item_embedding(batch['slates_item_indexes']).flatten(-3, -2)\n",
    "        if self.embeddings == 'explicit':\n",
    "            user_embs = batch['user_embeddings'][:, 0, :].unsqueeze(0).contiguous()\n",
    "            item_embs = batch['slates_item_embeddings'].flatten(-3, -2)\n",
    "\n",
    "        shp = batch['slates_item_indexes'].shape\n",
    "        rnn_out, _ = self.rnn_layer(\n",
    "            F.dropout(item_embs, p=0.1, training=self.training),\n",
    "            F.dropout(user_embs, p=0.1, training=self.training)\n",
    "        )\n",
    "        # rnn_out = F.dropout1d(rnn_out, p=0.1, training=self.training)\n",
    "        return self.out_layer(rnn_out).reshape([*shp, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb060fd-4f65-449b-9107-541d5c867a9d",
   "metadata": {},
   "source": [
    "# Игрушечный датасет: проверим, что сходится к идеальным метрикам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44dd16-46a4-441e-8e23-44d8888caa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DummyData()\n",
    "dummy_loader, dummy_svd = get_dummy_data(d)\n",
    "\n",
    "for embeddings in ['explicit', 'neural', 'svd']:\n",
    "    print(f\"Evaluating {experiment_name} embeddings\")\n",
    "    model = NeuralClickModel(\n",
    "        user_embedding_dim=2,\n",
    "        item_embedding_dim=2,\n",
    "        output_dim=1, \n",
    "        embeddings='neural' if embeddings == 'neural' else 'explicit', \n",
    "        num_items = d.n_items,\n",
    "        num_users = d.n_users\n",
    "    ).to(device)\n",
    "    _, metrics = train(model, \n",
    "       dummy_loader, dummy_loader, dummy_loader, encoder=dummy_svd if embeddings == 'svd' else None,\n",
    "       device=device, lr=1e-3, num_epochs=5000, \n",
    "       silent=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a0866-6615-44ce-86c4-1a406d4356a1",
   "metadata": {},
   "source": [
    "# ContentWise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fc476-45e7-4b21-9868-0f0b0be0dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_wise_results = []\n",
    "c = ContentWise.load('../cw.pkl')\n",
    "c_train_loader, c_val_loader, c_test_loader, c_svd_encoder = get_train_val_test_svd(c, batch_size=64)\n",
    "len(c_train_loader), len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed1106-d991-4200-aa1e-6bb0ee480210",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embeddings in ['svd', 'neural']:\n",
    "    print(f\"\\nEvaluating {experiment_name} with {embeddings} embeddings\")\n",
    "    model = NeuralClickModel(\n",
    "        num_items = c.n_items, num_users = c.n_users, \n",
    "        user_embedding_dim=c.user_features.shape[-1] if embeddings == 'explicit' else 32, \n",
    "        item_embedding_dim=c.item_features.shape[-1] if embeddings == 'explicit' else 32, \n",
    "        embeddings='neural' if embeddings == 'neural' else 'explicit', \n",
    "        output_dim=1, \n",
    "    ).to(device)\n",
    "\n",
    "    _, metrics = train(model, \n",
    "       c_train_loader, c_val_loader, c_test_loader, encoder=c_svd_encoder if embeddings == 'svd' else None,\n",
    "       device=device, lr=1e-3, num_epochs=5000, early_stopping=30,\n",
    "       silent=True, \n",
    "    )\n",
    "    \n",
    "    metrics['embeddings'] = embeddings\n",
    "    content_wise_results.append(metrics)\n",
    "    \n",
    "pd.DataFrame(content_wise_results).to_csv(f'results/cw_{experiment_name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6fb38-7a10-4774-9338-924677abeeef",
   "metadata": {},
   "source": [
    "# RL4RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c263123-b6f2-4e2c-b2e4-9d7343b7d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl4rs_results = []\n",
    "r = RL4RS.load('../rl4rs.pkl')\n",
    "r_train_loader, r_val_loader, r_test_loader, r_svd_encoder = get_train_val_test_svd(r, batch_size=128, )\n",
    "len(r), len(r_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93c297-9976-41da-853c-e72fa3ce5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embeddings in ['neural','explicit', 'svd',  ]:\n",
    "    print(f\"\\nEvaluating {experiment_name} with {embeddings} embeddings\")\n",
    "    model = NeuralClickModel(\n",
    "        num_items = r.n_items, num_users = r.n_users, \n",
    "        user_embedding_dim=r.user_features.shape[-1] if embeddings == 'explicit' else 32, \n",
    "        item_embedding_dim=r.item_features.shape[-1] if embeddings == 'explicit' else 32, \n",
    "        embeddings='neural' if embeddings == 'neural' else 'explicit', \n",
    "        output_dim=1, \n",
    "    ).to(device)\n",
    "    _, metrics = train(model, \n",
    "       r_train_loader, r_val_loader, r_test_loader, encoder=r_svd_encoder if embeddings == 'svd' else None,\n",
    "       device='cuda', lr=1e-3, num_epochs=5000, early_stopping=30,\n",
    "       silent=True\n",
    "    )\n",
    "    metrics['embeddings'] = embeddings\n",
    "    rl4rs_results.append(metrics)\n",
    "    \n",
    "pd.DataFrame(rl4rs_results).to_csv(f'results/rl4rs_{experiment_name}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
