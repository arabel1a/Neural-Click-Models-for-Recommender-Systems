{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05773a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe86de02b30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from src.datasets import RL4RS, ContentWise, DummyData, OpenCDP\n",
    "from src.utils import evaluate_model, get_dummy_data, get_train_val_test_tmatrix_tnumitems\n",
    "from src.embeddings import RecsysEmbedding\n",
    "\n",
    "experiment_name = 'MatrixFactorization'\n",
    "device = 'cuda:0'\n",
    "seed = 7331\n",
    "pkl_path = '../pkl/'\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474ce32",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8bcd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(torch.nn.Module):\n",
    "    def __init__(self, embedding):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        item_embs, user_embs = self.embedding(batch)\n",
    "        scores = item_embs * user_embs[:, :, None, :].repeat(1, 1, item_embs.size(-2), 1)\n",
    "        scores = scores.sum(-1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6c5aa",
   "metadata": {},
   "source": [
    "# ContentWise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f00b5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20216 data points among 108 batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.19776448607444763,\n",
       " 'roc-auc': 0.6526899337768555,\n",
       " 'accuracy': 0.2600274384021759,\n",
       " 'embeddings': 'svd'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ContentWise.load(os.path.join(pkl_path, 'cw.pkl'))\n",
    "(\n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    test_loader, \n",
    "    train_user_item_matrix, \n",
    "    train_num_items\n",
    ") = get_train_val_test_tmatrix_tnumitems(dataset, batch_size=150)\n",
    "\n",
    "print(f\"{len(dataset)} data points among {len(train_loader)} batches\")\n",
    "\n",
    "model = MF(\n",
    "    RecsysEmbedding(dataset.n_items, train_user_item_matrix, embeddings='svd'),\n",
    ").to('cpu')\n",
    "\n",
    "test_scores = evaluate_model(model, test_loader, device='cpu', silent=True, debug=False)\n",
    "test_scores['embeddings'] = 'svd'\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a7cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({key:[test_scores[key]] for key in test_scores}).to_csv(f'results/cw_MatrixFactorization.csv')\n",
    "del dataset, train_loader, val_loader, test_loader, train_user_item_matrix, train_num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154472b1",
   "metadata": {},
   "source": [
    "# RL4RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e394da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45942 data points among 106 batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.761080265045166,\n",
       " 'roc-auc': 0.7169578075408936,\n",
       " 'accuracy': 0.659001350402832,\n",
       " 'embeddings': 'svd'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = RL4RS.load(os.path.join(pkl_path, 'rl4rs.pkl'))\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    train_user_item_matrix,\n",
    "    train_num_items \n",
    ") = get_train_val_test_tmatrix_tnumitems(dataset, batch_size=350)\n",
    "\n",
    "print(f\"{len(dataset)} data points among {len(train_loader)} batches\")\n",
    "\n",
    "model = MF(\n",
    "    RecsysEmbedding(dataset.n_items, train_user_item_matrix, embeddings='svd'),\n",
    ").to('cpu')\n",
    "\n",
    "test_scores = evaluate_model(model, test_loader, device='cpu', silent=True, debug=False)\n",
    "test_scores['embeddings'] = 'svd'\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02bbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({key:[test_scores[key]] for key in test_scores}).to_csv(f'results/rl4rs_MatrixFactorization.csv')\n",
    "del dataset, train_loader, val_loader, test_loader, train_user_item_matrix, train_num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f670c8e-7e85-4e86-88d6-228b9a299432",
   "metadata": {},
   "source": [
    "# OpenCDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c429b8-8b35-406d-95a5-35310f61cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " == cosmetics_10_8.pkl ==\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OpenCDP' object has no attribute 'item_categorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m OpenCDP\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pkl_path, filename))\n\u001b[1;32m      7\u001b[0m (\n\u001b[1;32m      8\u001b[0m     train_loader, \n\u001b[1;32m      9\u001b[0m     val_loader,\n\u001b[1;32m     10\u001b[0m     test_loader, \n\u001b[1;32m     11\u001b[0m     train_user_item_matrix, \n\u001b[1;32m     12\u001b[0m     train_num_items\n\u001b[0;32m---> 13\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mget_train_val_test_tmatrix_tnumitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data points among \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m MF(\n\u001b[1;32m     18\u001b[0m     RecsysEmbedding(dataset\u001b[38;5;241m.\u001b[39mn_items, train_user_item_matrix, embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     19\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/benchmark/src/utils.py:36\u001b[0m, in \u001b[0;36mget_train_val_test_tmatrix_tnumitems\u001b[0;34m(dataset, train_frac, val_vs_test_frac, batch_size, seed, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_train_val_test_tmatrix_tnumitems\u001b[39m(dataset, train_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, val_vs_test_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m        Splits datset into train, test and val parts by given fractions.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m        The `train_frac` of users in dataset will be train set, and the rest is splitted \u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        into val and test in `val_vs_test_frac` proportion.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     train, rem \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_by_users\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_frac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     val, test \u001b[38;5;241m=\u001b[39m rem\u001b[38;5;241m.\u001b[39msplit_by_users(val_vs_test_frac, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m     39\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     40\u001b[0m         train,\n\u001b[1;32m     41\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     45\u001b[0m     )\n",
      "File \u001b[0;32m~/benchmark/src/datasets.py:241\u001b[0m, in \u001b[0;36mRecommendationData.split_by_users\u001b[0;34m(self, ratio, seed, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m m1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(train_users)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    239\u001b[0m m2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(test_users)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_metadata(m2, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    243\u001b[0m )\n",
      "File \u001b[0;32m~/benchmark/src/datasets.py:169\u001b[0m, in \u001b[0;36mRecommendationData._from_metadata\u001b[0;34m(self, metadata, inplace, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     item_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_features[m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_feature_idx\u001b[39m\u001b[38;5;124m'\u001b[39m],:]\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_categorical\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     item_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_categorical[m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_feature_idx\u001b[39m\u001b[38;5;124m'\u001b[39m],:]\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenCDP' object has no attribute 'item_categorical'"
     ]
    }
   ],
   "source": [
    "# cosmetics\n",
    "for filename in os.listdir(pkl_path):\n",
    "    if not filename.startswith('cosmetics'):\n",
    "        continue\n",
    "    print(f\"\\n == {filename} ==\")\n",
    "    dataset = OpenCDP.load(os.path.join(pkl_path, filename))\n",
    "    (\n",
    "        train_loader, \n",
    "        val_loader,\n",
    "        test_loader, \n",
    "        train_user_item_matrix, \n",
    "        train_num_items\n",
    "    ) = get_train_val_test_tmatrix_tnumitems(dataset, batch_size=200)\n",
    "\n",
    "    print(f\"{len(dataset)} data points among {len(train_loader)} batches\")\n",
    "\n",
    "    model = MF(\n",
    "        RecsysEmbedding(dataset.n_items, train_user_item_matrix, embeddings='svd'),\n",
    "    ).to('cpu')\n",
    "    \n",
    "    test_scores = evaluate_model(model, test_loader, device='cpu', silent=True, debug=False)\n",
    "    test_scores['embeddings'] = 'svd'\n",
    "    print(test_scores)\n",
    "    pd.DataFrame({key:[test_scores[key]] for key in test_scores}).to_csv(f'results/{filename}_MatrixFactorization.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
