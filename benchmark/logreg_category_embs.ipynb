{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183295d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f107372abb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from src.datasets import RL4RS, ContentWise, DummyData, OpenCDP\n",
    "from src.utils import train, get_dummy_data, get_train_val_test_tmatrix_tnumitems\n",
    "from src.embeddings import RecsysEmbedding, IndexItemEmbeddings, CategoricalItemEmbeddings, SVDItemEmbeddings, MixedEmbeddings\n",
    "\n",
    "experiment_name = 'LogRegCE'\n",
    "device = 'cuda:0'\n",
    "seed = 7331\n",
    "pkl_path = '../pkl/'\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17d656",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6060e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, embedding, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.linear = torch.nn.Linear(2 * embedding.embedding_dim, output_dim)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        item_embs, user_embs = self.embedding(batch)\n",
    "\n",
    "        features = torch.cat(\n",
    "            [\n",
    "                item_embs,\n",
    "                user_embs[:, :, None, :].repeat(1, 1, item_embs.size(-2), 1)\n",
    "            ],\n",
    "            dim = -1\n",
    "        )\n",
    "        return self.linear(features).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbef021-2fb8-4434-b94f-2f243db7ba83",
   "metadata": {},
   "source": [
    "# Проверка категориальных фичей\n",
    "\n",
    "### Dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79dced5-600e-46b2-9d65-7d0859f8af73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosmetics_10_1.pkl   cosmetics_20_8.pkl  multi_10_1.pkl   multi_20_8.pkl\n",
      "cosmetics_10_2.pkl   cosmetics_5_1.pkl\t multi_10_2.pkl   multi_5_1.pkl\n",
      "cosmetics_10_24.pkl  cosmetics_5_2.pkl\t multi_10_24.pkl  multi_5_2.pkl\n",
      "cosmetics_10_4.pkl   cosmetics_5_24.pkl  multi_10_4.pkl   multi_5_24.pkl\n",
      "cosmetics_10_8.pkl   cosmetics_5_4.pkl\t multi_10_8.pkl   multi_5_4.pkl\n",
      "cosmetics_20_1.pkl   cosmetics_5_8.pkl\t multi_20_1.pkl   multi_5_8.pkl\n",
      "cosmetics_20_2.pkl   cosmetics_8_24.pkl  multi_20_2.pkl   rl4rs.pkl\n",
      "cosmetics_20_24.pkl  cw.pkl\t\t multi_20_24.pkl\n",
      "cosmetics_20_4.pkl   ilya_pkl\t\t multi_20_4.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls ../pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d6af66-7928-425f-9e58-92bb6452654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biulding affinity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 3410.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 data points among 1 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test before learning: {'f1': 0.0, 'roc-auc': 0.3333333134651184, 'accuracy': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train... loss:0.7032778263092041:   0%|                                                                                                    | 1/5000 [00:00<25:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val update: epoch: 0 |accuracy: 0.5 | f1: 0.5 | auc: 0.6666666269302368 | treshold: 0.38\n",
      "Test: accuracy: 0.5 | f1: 0.5 | auc: 0.6666666269302368 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train... loss:0.6855418086051941:   0%|                                                                                                    | 3/5000 [00:00<23:11,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val update: epoch: 2 |accuracy: 0.75 | f1: 0.6666666865348816 | auc: 0.6666666269302368 | treshold: 0.42000000000000004\n",
      "Test: accuracy: 0.75 | f1: 0.6666666865348816 | auc: 0.6666666269302368 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train... loss:0.4575468599796295:   1%|▋                                                                                                  | 34/5000 [00:07<20:01,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val update: epoch: 33 |accuracy: 0.75 | f1: 0.6666666865348816 | auc: 1.0 | treshold: 0.29000000000000004\n",
      "Test: accuracy: 0.75 | f1: 0.6666666865348816 | auc: 1.0 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train... loss:0.451371967792511:   1%|▋                                                                                                   | 35/5000 [00:08<19:03,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val update: epoch: 35 |accuracy: 1.0 | f1: 1.0 | auc: 1.0 | treshold: 0.51\n",
      "Test: accuracy: 1.0 | f1: 1.0 | auc: 1.0 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(\n",
       "   (embedding): MixedEmbeddings(\n",
       "     (embeddings): ModuleList(\n",
       "       (0): IndexItemEmbeddings(\n",
       "         (embeddings): Embedding(6, 32)\n",
       "       )\n",
       "       (1): SVDItemEmbeddings()\n",
       "       (2): CategoricalItemEmbeddings(\n",
       "         (embeddings): ModuleList(\n",
       "           (0): Embedding(5, 8)\n",
       "           (1): Embedding(5, 8)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       " ),\n",
       " {'f1': 1.0, 'roc-auc': 1.0, 'accuracy': 1.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = #OpenCDP.load(os.path.join(pkl_path, 'cosmetics_10_24.pkl'))\n",
    "dataset=DummyData()\n",
    "train_loader, train_user_item_matrix = get_dummy_data(dataset)\n",
    "# (\n",
    "#     train_loader, \n",
    "#     val_loader,\n",
    "#     test_loader, \n",
    "#     train_user_item_matrix, \n",
    "#     train_num_items\n",
    "# ) = get_train_val_test_tmatrix_tnumitems(dataset, batch_size=800)\n",
    "print(f\"{len(dataset)} data points among {len(train_loader)} batches\")\n",
    "index_embeddings = IndexItemEmbeddings(dataset.n_items, embedding_dim = 32)\n",
    "category_embeddings = CategoricalItemEmbeddings(dataset.item_categorical)\n",
    "svd_embeddings = SVDItemEmbeddings(train_user_item_matrix, embedding_dim=2)\n",
    "\n",
    "me = MixedEmbeddings(\n",
    "    index_embeddings,\n",
    "    svd_embeddings,\n",
    "    category_embeddings\n",
    ")\n",
    "\n",
    "model = LogisticRegression(me, output_dim=1)\n",
    "train(\n",
    "    model, \n",
    "    train_loader, train_loader, train_loader, \n",
    "    device=device, lr=1e-3, num_epochs=5000, early_stopping=7,\n",
    "    silent=True, \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a11765-07e3-41a5-b869-470065125d5d",
   "metadata": {},
   "source": [
    "# OpenCDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c564c2c2-310d-426e-b68c-335694a21716",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OpenCDP.load(os.path.join(pkl_path, 'cosmetics_8_24.pkl'))\n",
    "(\n",
    "    train_loader, \n",
    "    val_loader,\n",
    "    test_loader, \n",
    "    train_user_item_matrix, \n",
    "    train_num_items\n",
    ") = get_train_val_test_tmatrix_tnumitems(dataset, batch_size=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b39be1-7d83-4ae8-969f-4b47bb91f06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['slates_item_categorical'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c57d1d-f53e-42a0-9b46-abd1a1067656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117994 data points among 119 batches\n",
      "Test before learning: {'f1': 0.3339962065219879, 'roc-auc': 0.502016007900238, 'accuracy': 0.4820767641067505}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train... loss:82.06898438930511:   0%|                                                                                                | 1/5000 [06:59<582:17:57, 419.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val update: epoch: 0 |accuracy: 0.5213140845298767 | f1: 0.6853435635566711 | auc: 0.5650879144668579 | treshold: 0.22\n",
      "Test: accuracy: 0.5315372347831726 | f1: 0.6941224932670593 | auc: 0.5629243850708008 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train... loss:80.0679235458374:   0%|                                                                                                 | 2/5000 [07:18<255:44:04, 184.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val update: epoch: 1 |accuracy: 0.534050464630127 | f1: 0.6878179311752319 | auc: 0.6120887398719788 | treshold: 0.38\n",
      "Test: accuracy: 0.5428749918937683 | f1: 0.6963071823120117 | auc: 0.6127125024795532 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train... loss:80.0679235458374:   0%|                                                                                                 | 2/5000 [07:32<314:12:55, 226.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m me \u001b[38;5;241m=\u001b[39m MixedEmbeddings(\n\u001b[1;32m      8\u001b[0m     index_embeddings,\n\u001b[1;32m      9\u001b[0m     svd_embeddings,\n\u001b[1;32m     10\u001b[0m     category_embeddings\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(me, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/benchmark/src/utils.py:302\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, test_loader, device, lr, num_epochs, silent, early_stopping, debug, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# prediction_shape: (batch_size, max_sequence, 'max_slate, 2)\u001b[39;00m\n\u001b[1;32m    297\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\n\u001b[1;32m    298\u001b[0m     raw_scores[mask], \n\u001b[1;32m    299\u001b[0m     corrects[mask],\n\u001b[1;32m    300\u001b[0m )\n\u001b[0;32m--> 302\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# print(loss.item())\u001b[39;00m\n\u001b[1;32m    304\u001b[0m mean_grad_norm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m clip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"{len(dataset)} data points among {len(train_loader)} batches\")\n",
    "\n",
    "index_embeddings = IndexItemEmbeddings(dataset.n_items, embedding_dim = 32)\n",
    "category_embeddings = CategoricalItemEmbeddings(dataset.item_categorical)\n",
    "svd_embeddings = SVDItemEmbeddings(train_user_item_matrix, embedding_dim=32)\n",
    "\n",
    "me = MixedEmbeddings(\n",
    "    index_embeddings,\n",
    "    svd_embeddings,\n",
    "    category_embeddings\n",
    ")\n",
    "\n",
    "model = LogisticRegression(me, output_dim=1)\n",
    "train(\n",
    "    model, \n",
    "    train_loader, val_loader, test_loader, \n",
    "    device=device, lr=1e-3, num_epochs=5000, early_stopping=7,\n",
    "    silent=True, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
